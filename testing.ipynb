{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Region of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_between_keypoints(img, x, y):\n",
    "    height, width = img.shape\n",
    "    \n",
    "    x, y = int(x), int(y)\n",
    "    \n",
    "    # Calculate bounding box around the keypoint\n",
    "    left = max(0, x - width // 2)\n",
    "    right = min(width, x + width // 2)\n",
    "    top = max(0, y - height // 2)\n",
    "    bottom = min(height, y + height // 2)\n",
    "\n",
    "    # Crop the image\n",
    "    return img[top:bottom, left:right]\n",
    "\n",
    "\n",
    "def crop_around_keypoint(img, keypoint, width, height):\n",
    "    h, w = img.shape\n",
    "    \n",
    "    x, y = int(keypoint[0]), int(keypoint[1])\n",
    "    \n",
    "    # Calculate bounding box around the keypoint\n",
    "    left = max(0, x - width // 2)\n",
    "    right = min(w, x + width // 2)\n",
    "    top = max(0, y - height // 2)\n",
    "    bottom = min(h, y + height // 2)\n",
    "    \n",
    "    # Crop the image\n",
    "    return img[top:bottom, left:right]\n",
    "\n",
    "def graph_plot(study_id, series_id):\n",
    "    train_label_combinations = pl.DataFrame()\n",
    "    for row in train_label.iter_rows():\n",
    "        if row[0]==study_id:\n",
    "            print(pl.DataFrame(row[:3]).transpose())\n",
    "            data = pl.DataFrame(row[:3]).transpose()\n",
    "            train_label_combinations=pl.concat([train_label_combinations, data])\n",
    "    print(train_label_combinations)\n",
    "    \n",
    "    #rename columns\n",
    "    train_label_combinations = train_label_combinations.rename({\"column_0\":\"study_id\", \"column_1\":\"series_id\", \"column_2\":\"instance_number\"})\n",
    "    #extract unique combination\n",
    "    train_label_combinations = train_label_combinations.unique(subset=[\"study_id\", \"series_id\", \"instance_number\"]).sort([\"study_id\", \"series_id\", \"instance_number\"])\n",
    "    \n",
    "    instance_number_list = train_label_combinations.filter((pl.col(\"study_id\")==study_id) & (pl.col(\"series_id\")==series_id)).get_column(\"instance_number\")\n",
    "    #instance_number_list\n",
    "\n",
    "    for instance_number in instance_number_list:\n",
    "        #print(instance_number)\n",
    "        print(f\"=====study_id:{study_id}, series_id:{series_id}, instance_number:{instance_number}=====\")\n",
    "        #read image\n",
    "        ds = pydicom.read_file(f'{INPUT_DIR}/train_images/{study_id}/{series_id}/{instance_number}.dcm')\n",
    "        #draw original image\n",
    "        df_plt = train_label.filter(\n",
    "            (pl.col('study_id')==study_id)\n",
    "            &(pl.col('series_id')==series_id)\n",
    "            &(pl.col('instance_number')==instance_number)\n",
    "        )\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(ds.pixel_array, cmap='bone')\n",
    "        #plt.title(f\"study_id:{study_id}, series_id:{series_id}, instance_number:{instance_number}\")\n",
    "\n",
    "        #draw original image + label\n",
    "        #draw image\n",
    "        df_plt = train_label.filter(\n",
    "            (pl.col('study_id')==study_id)\n",
    "            &(pl.col('series_id')==series_id)\n",
    "            &(pl.col('instance_number')==instance_number)\n",
    "        )\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(ds.pixel_array, cmap='bone')\n",
    "        #plt.title(f\"study_id:{study_id}, series_id:{series_id}, instance_number:{instance_number}\")\n",
    "        #draw rabel\n",
    "        for row in df_plt.iter_rows():\n",
    "            plt.scatter(row[-2], row[-1], color='red')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom as dicom\n",
    "\n",
    "study_id, series_id = 4290709089, 3274612423\n",
    "instance_number = 5\n",
    "directory =f'{INPUT_DIR}/train_images/{study_id}/{series_id}/{instance_number}.dcm'\n",
    "\n",
    "def paddingOrCroppingImage(directory):\n",
    "    ds=dicom.dcmread(directory)\n",
    "    \n",
    "    dcm_data=ds.pixel_array\n",
    "    # Example target size (height, width)\n",
    "    target_height, target_width = 512, 512\n",
    "\n",
    "    # Current image shape\n",
    "    current_height, current_width = dcm_data.shape\n",
    "    print(current_height, current_width)\n",
    "\n",
    "    if current_height > target_height or current_width > target_width:\n",
    "        crop_top = (current_height - target_height) // 2\n",
    "        crop_bottom = crop_top + target_height\n",
    "        crop_left = (current_width - target_width) // 2\n",
    "        crop_right = crop_left + target_width\n",
    "\n",
    "        cropped_image = dcm_data[crop_top:crop_bottom, crop_left:crop_right]\n",
    "        return cropped_image\n",
    "    else:\n",
    "        # Calculate padding sizes\n",
    "        pad_height = max(0, target_height - current_height)\n",
    "        pad_width = max(0, target_width - current_width)\n",
    "\n",
    "        # Calculate the padding to apply to each side\n",
    "        pad_top = pad_height // 2\n",
    "        pad_bottom = pad_height - pad_top\n",
    "        pad_left = pad_width // 2\n",
    "        pad_right = pad_width - pad_left\n",
    "\n",
    "\n",
    "        # Apply padding with replicated borders\n",
    "        padded_image = cv2.copyMakeBorder(\n",
    "            dcm_data,\n",
    "            pad_top,\n",
    "            pad_bottom,\n",
    "            pad_left,\n",
    "            pad_right,\n",
    "            cv2.BORDER_REPLICATE\n",
    "        )\n",
    "\n",
    "        # Update Dicom metadata\n",
    "        ds.Rows, ds.Columns = padded_image.shape\n",
    "        ds.PixelData = padded_image.tobytes()\n",
    "        print(pad_top, pad_bottom, pad_left, pad_right)\n",
    "        return padded_image\n",
    "    \n",
    "\n",
    "def reversed_images_cropping(image):\n",
    "    current_height, current_width = image.shape\n",
    "    target_height, target_width = 320, 320\n",
    "\n",
    "    crop_top = (current_height - target_height) // 2\n",
    "    crop_bottom = crop_top + target_height\n",
    "    crop_left = (current_width - target_width) // 2\n",
    "    crop_right = crop_left + target_width\n",
    "\n",
    "    cropped_image = image[crop_top:crop_bottom, crop_left:crop_right]\n",
    "    return cropped_image\n",
    "    \n",
    "\n",
    "dfs = train_label.filter(\n",
    "            (pl.col('study_id')==study_id)\n",
    "            &(pl.col('series_id')==series_id)\n",
    "            &(pl.col('instance_number')==instance_number)\n",
    "        )\n",
    "for row in dfs.iter_rows():\n",
    "        plt.scatter(row[-2], row[-1], color='red')\n",
    "\n",
    "        \n",
    "updated_image = paddingOrCroppingImage(directory)\n",
    "reversed_image = reversed_images_cropping(updated_image)\n",
    "\n",
    "plt.figure(figsize=(10, 5))  # Adjust figure size if needed\n",
    "\n",
    "# Plot the updated (cropped/padded) image on the left\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(updated_image, cmap='gray')  # Use 'gray' colormap for grayscale images\n",
    "plt.title('Updated Image')\n",
    "plt.axis('off')  # Turn off axis labels\n",
    "\n",
    "# Plot the reversed image on the right\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(reversed_image, cmap='gray')\n",
    "plt.title('Reversed Image')\n",
    "plt.axis('off')  # Turn off axis labels\n",
    "\n",
    "# Show the plot with both images\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import pydicom as dicom\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def structure_for_train_csv(condition):\n",
    "    condition = condition.lower().replace(' ', '_').replace('/', '_')\n",
    "    return condition\n",
    "class SpinalDataset(Dataset):\n",
    "    def __init__(self, root_dir, coordinates_file, train, train_data, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.coordinates = pd.read_csv(coordinates_file)\n",
    "        self.train_data = pd.read_csv(train_data)\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "\n",
    "        # Perform imputation on the training data\n",
    "        self.train_data = self.impute_missing_values(self.train_data)\n",
    "\n",
    "        # Define label encoder and one hot encoder\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "        # Fit the label encoder and one hot encoder\n",
    "        conditions = [\"Normal/Mild\", \"Moderate\", \"Severe\"]\n",
    "\n",
    "        self.label_encoder.fit(conditions)\n",
    "        integer_encoded = self.label_encoder.transform(conditions).reshape(-1, 1)\n",
    "        self.onehot_encoder.fit(integer_encoded)\n",
    "\n",
    "        # Define sample weights\n",
    "        self.weights = {\"Normal/Mild\": 1, \"Moderate\": 2, \"Severe\": 4}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.coordinates)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.coordinates.iloc[idx]\n",
    "        study_id = row['study_id']\n",
    "        series_id = row['series_id']\n",
    "        instance = row['instance_number']\n",
    "        condition = row['condition']\n",
    "        level = row['level']\n",
    "        x = row['x']\n",
    "        y = row['y'] \n",
    "\n",
    "        # Construct the path to the DICOM\n",
    "        dicom_file_path = os.path.join(self.root_dir, self.train, str(study_id), str(series_id), f\"{instance}.dcm\")\n",
    "        \n",
    "       # Load and process the DICOM image\n",
    "        images, crop_top, crop_left = self.load_and_process_dicom_image(dicom_file_path)\n",
    "\n",
    "        if self.transform:\n",
    "            images = self.transform(images)\n",
    "\n",
    "        # Adjust coordinates based on whether the image was cropped or padded\n",
    "        if crop_top >= 0 and crop_left >= 0:\n",
    "            adjusted_x, adjusted_y = self.adjust_coordinates_after_cropping(x, y, crop_top, crop_left)\n",
    "        else:\n",
    "            adjusted_x, adjusted_y = self.adjust_coordinates_after_padding(x, y, -crop_top, -crop_left)\n",
    "\n",
    "        # Extract condition for the specified level\n",
    "        condition_column = f'{condition}_{level}'\n",
    "        condition_column = structure_for_train_csv(condition_column)\n",
    "        label_str = self.train_data.loc[self.train_data['study_id'] == study_id, condition_column].values[0]\n",
    "\n",
    "        # Encode the label\n",
    "        label_encoded = self.label_encoder.transform([label_str])\n",
    "        label_onehot = self.onehot_encoder.transform(label_encoded.reshape(-1, 1))\n",
    "        label = torch.tensor(label_onehot, dtype=torch.float32).squeeze()\n",
    "\n",
    "        print(f\"Label string: {label_str}\")\n",
    "        \n",
    "        # Calculate weight for the sample\n",
    "        weight = self.weights.get(label_str, 1)  # Default to 1 if condition not found\n",
    "\n",
    "        return images, label, weight, adjusted_x, adjusted_y\n",
    "    \n",
    "    def load_and_process_dicom_image(self, file_path):\n",
    "        dicom = pydicom.dcmread(file_path)\n",
    "        image = dicom.pixel_array\n",
    "        \n",
    "        # Normalize the pixel values to [0, 1]\n",
    "        image = image.astype(np.float32) / image.max()\n",
    "\n",
    "        # Crop or pad the image as needed\n",
    "        if image.shape[0] > 512 or image.shape[1] > 512:\n",
    "            image, crop_top, crop_left = self.crop_image(image)\n",
    "        else:\n",
    "            image, crop_top, crop_left = self.pad_image(image)\n",
    "        \n",
    "        return image, crop_top, crop_left\n",
    "\n",
    "\n",
    "    def crop_image(self, image):\n",
    "        target_height, target_width = 512, 512\n",
    "        current_height, current_width = image.shape\n",
    "\n",
    "        crop_top = (current_height - target_height) // 2\n",
    "        crop_bottom = crop_top + target_height\n",
    "        crop_left = (current_width - target_width) // 2\n",
    "        crop_right = crop_left + target_width\n",
    "\n",
    "        cropped_image = image[crop_top:crop_bottom, crop_left:crop_right]\n",
    "        return cropped_image, crop_top, crop_left\n",
    "\n",
    "    def pad_image(self, image):\n",
    "        target_height, target_width = 512, 512\n",
    "        current_height, current_width = image.shape\n",
    "\n",
    "        pad_height = max(0, target_height - current_height)\n",
    "        pad_width = max(0, target_width - current_width)\n",
    "\n",
    "        pad_top = pad_height // 2\n",
    "        pad_bottom = pad_height - pad_top\n",
    "        pad_left = pad_width // 2\n",
    "        pad_right = pad_width - pad_left\n",
    "\n",
    "        padded_image = cv2.copyMakeBorder(\n",
    "            image,\n",
    "            pad_top,\n",
    "            pad_bottom,\n",
    "            pad_left,\n",
    "            pad_right,\n",
    "            cv2.BORDER_REPLICATE\n",
    "        )\n",
    "        # Ensure final image size is exactly 512x512\n",
    "        padded_image = cv2.resize(padded_image, (512, 512), interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        return padded_image, -pad_top, -pad_left\n",
    "\n",
    "\n",
    "    def adjust_coordinates_after_cropping(self, x, y, crop_top, crop_left):\n",
    "        \"\"\"\n",
    "        Adjusts x and y coordinates after cropping.\n",
    "        \"\"\"\n",
    "        adjusted_x = x - crop_left\n",
    "        adjusted_y = y - crop_top\n",
    "        return adjusted_x, adjusted_y\n",
    "\n",
    "    def adjust_coordinates_after_padding(self, x, y, pad_top, pad_left):\n",
    "        \"\"\"\n",
    "        Adjusts x and y coordinates after padding.\n",
    "        \"\"\"\n",
    "        adjusted_x = x + pad_left\n",
    "        adjusted_y = y + pad_top\n",
    "        return adjusted_x, adjusted_y\n",
    "    \n",
    "    def impute_missing_values(self, df):\n",
    "        # Select categorical columns for imputation\n",
    "        categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "        # Initialize the SimpleImputer for categorical columns\n",
    "        categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "        # Fit and transform the categorical columns\n",
    "        df[categorical_columns] = categorical_imputer.fit_transform(df[categorical_columns])\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Example usage\n",
    "dataset = SpinalDataset(root_dir=INPUT_DIR, \n",
    "                        coordinates_file=f'{INPUT_DIR}/train_label_coordinates.csv', \n",
    "                        train='train_images',\n",
    "                        train_data=f'{INPUT_DIR}/train.csv')\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "for images, labels, weights, x, y in dataloader:\n",
    "    print(\"Images shape:\", images.shape)\n",
    "    print(\"Labels:\", labels)\n",
    "    print(\"Weights:\", weights)\n",
    "    print(f\"x: {x}\")\n",
    "    print(f\"y: {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking and adding padding and cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom as dicom\n",
    "import polars as pl\n",
    "\n",
    "def paddingOrCroppingImage(dcm_data, target_height=512, target_width=512):\n",
    "    current_height, current_width = dcm_data.shape\n",
    "\n",
    "    if current_height > target_height or current_width > target_width:\n",
    "        # Cropping\n",
    "        crop_top = (current_height - target_height) // 2\n",
    "        crop_bottom = crop_top + target_height\n",
    "        crop_left = (current_width - target_width) // 2\n",
    "        crop_right = crop_left + target_width\n",
    "\n",
    "        cropped_image = dcm_data[crop_top:crop_bottom, crop_left:crop_right]\n",
    "        return cropped_image, crop_top, crop_left\n",
    "    else:\n",
    "        # Padding\n",
    "        pad_height = max(0, target_height - current_height)\n",
    "        pad_width = max(0, target_width - current_width)\n",
    "\n",
    "        pad_top = pad_height // 2\n",
    "        pad_bottom = pad_height - pad_top\n",
    "        pad_left = pad_width // 2\n",
    "        pad_right = pad_width - pad_left\n",
    "\n",
    "        padded_image = cv2.copyMakeBorder(\n",
    "            dcm_data,\n",
    "            pad_top,\n",
    "            pad_bottom,\n",
    "            pad_left,\n",
    "            pad_right,\n",
    "            cv2.BORDER_REPLICATE\n",
    "        )\n",
    "        return padded_image, -pad_top, -pad_left  # Return negative padding as we need to add these to coordinates\n",
    "\n",
    "def reversed_images_cropping(image, target_height=320, target_width=320):\n",
    "    current_height, current_width = image.shape\n",
    "\n",
    "    crop_top = (current_height - target_height) // 2\n",
    "    crop_bottom = crop_top + target_height\n",
    "    crop_left = (current_width - target_width) // 2\n",
    "    crop_right = crop_left + target_width\n",
    "\n",
    "    cropped_image = image[crop_top:crop_bottom, crop_left:crop_right]\n",
    "    return cropped_image\n",
    "\n",
    "def graph_plot(study_id, series_id):\n",
    "    instance_number_list = train_label.filter(\n",
    "        (pl.col(\"study_id\") == study_id) & \n",
    "        (pl.col(\"series_id\") == series_id)\n",
    "    ).select(\"instance_number\").unique().sort(\"instance_number\").to_series().to_list()\n",
    "\n",
    "    for instance_number in instance_number_list:\n",
    "        ds = dicom.dcmread(f'{INPUT_DIR}/train_images/{study_id}/{series_id}/{instance_number}.dcm')\n",
    "        original_image = ds.pixel_array\n",
    "\n",
    "        updated_image, crop_top, crop_left = paddingOrCroppingImage(original_image)\n",
    "        reversed_image = reversed_images_cropping(updated_image)\n",
    "\n",
    "        df_plt = train_label.filter(\n",
    "            (pl.col('study_id') == study_id) &\n",
    "            (pl.col('series_id') == series_id) &\n",
    "            (pl.col('instance_number') == instance_number)\n",
    "        )\n",
    "\n",
    "        plt.figure(figsize=(15, 5))\n",
    "\n",
    "        # Original Image\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(original_image, cmap='gray')\n",
    "        plt.title('Original Image')\n",
    "        plt.axis('off')\n",
    "        for row in df_plt.iter_rows():\n",
    "            plt.scatter(row[-2], row[-1], color='red')  # Coordinates for original image\n",
    "\n",
    "        # Updated Image (Cropped/Padded)\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(updated_image, cmap='gray')\n",
    "        plt.title('Updated Image')\n",
    "        plt.axis('off')\n",
    "        for row in df_plt.iter_rows():\n",
    "            plt.scatter(row[-2] - crop_left, row[-1] - crop_top, color='red')  # Adjusted coordinates for padding/cropping\n",
    "\n",
    "        # Reversed Image (Final Cropping)\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(reversed_image, cmap='gray')\n",
    "        plt.title('Reversed Image')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Adjust coordinates for the final cropping\n",
    "        reverse_crop_top = (updated_image.shape[0] - reversed_image.shape[0]) // 2\n",
    "        reverse_crop_left = (updated_image.shape[1] - reversed_image.shape[1]) // 2\n",
    "\n",
    "        for row in df_plt.iter_rows():\n",
    "            adjusted_x = row[-2] - crop_left - reverse_crop_left\n",
    "            adjusted_y = row[-1] - crop_top - reverse_crop_top\n",
    "            print(adjusted_x, adjusted_x)\n",
    "            plt.scatter(adjusted_x, adjusted_y, color='red')  # Adjusted for final cropping\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "# Example usage:\n",
    "study_id, series_id = 4290709089, 3274612423\n",
    "graph_plot(study_id, series_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting Nnumber of images and min and maxheight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to image directory\n",
    "image_dir = \"rsna-2024-lumbar-spine-degenerative-classification/train_images/\"\n",
    "\n",
    "def findingShape():\n",
    "    # Initialize variable to store minimum width and minimum height\n",
    "    # min_width, min_height = float('inf'), float('inf')\n",
    "    total_height, total_width, num_images = 0, 0, 0\n",
    "    maxheight, maxwidth = 0, 0\n",
    "\n",
    "    # Iterate through all images in the directoey\n",
    "    for image_name in os.listdir(image_dir):\n",
    "        study_dir = os.path.join(image_dir, image_name)\n",
    "        if not os.path.isdir(study_dir):\n",
    "            continue\n",
    "\n",
    "        for series_id in os.listdir(study_dir):\n",
    "            series_dir = os.path.join(study_dir, series_id)\n",
    "            if not os.path.isdir(series_dir):\n",
    "                continue\n",
    "\n",
    "            for dicom_file in os.listdir(series_dir):\n",
    "                dicom_path = os.path.join(series_dir, dicom_file)\n",
    "\n",
    "                try:\n",
    "                    ds = pydicom.dcmread(dicom_path)\n",
    "                    image_array = ds.pixel_array\n",
    "                    \n",
    "                    if len(image_array.shape) == 2:  # Grayscale size\n",
    "                        height, width = image_array.shape\n",
    "                        print(f\"Height: {image_array.shape[0]}, width: {image_array.shape[1]}, Image count\")\n",
    "\n",
    "                    elif len(image_array.shape) == 3:  # Color including \n",
    "                        height, width, _ = image_array.shape\n",
    "                        print(dicom_path)\n",
    "                        \n",
    "                    else:\n",
    "                        raise ValueError(f\"Unexpected image shape: {image_array.shape}\")\n",
    "\n",
    "                    # Accumulate total size\n",
    "                    maxheight = max(maxheight, height)\n",
    "                    maxwidth = max(maxwidth, width)\n",
    "                    total_width += width\n",
    "                    total_height += height\n",
    "                    num_images += 1\n",
    "                    print(num_images)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to process {dicom_path}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "    # Calculate average \n",
    "    if num_images > 0:\n",
    "        avg_width = total_width // num_images\n",
    "        avg_height = total_height // num_images\n",
    "        print(f\"Average Width: {avg_width}, Average Height: {avg_height}, maxheight: {maxheight}, maxwidth: {maxwidth}\")\n",
    "    else: \n",
    "        print(\"No images\")\n",
    "\n",
    "findingShape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Auto hot coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# Define the conditions\n",
    "conditions = [\"Normal/Mild\", \"Moderate\", \"Severe\"]\n",
    "\n",
    "# Initialize and fit the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(conditions)\n",
    "\n",
    "# Convert labels to numerical values\n",
    "integer_encoded = label_encoder.transform(conditions).reshape(-1, 1)\n",
    "\n",
    "# Initialize and fit the OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "onehot_encoder.fit(integer_encoded)\n",
    "\n",
    "# Example labels to encode\n",
    "labels = [\"Normal/Mild\", \"Moderate\", \"Severe\"]\n",
    "\n",
    "# Convert to numerical labels\n",
    "integer_encoded = label_encoder.transform(labels).reshape(-1, 1)\n",
    "\n",
    "# Convert to one-hot encoded vectors\n",
    "onehot_encoded = onehot_encoder.transform(integer_encoded)\n",
    "\n",
    "print(\"Integer Encoded:\")\n",
    "print(integer_encoded)\n",
    "\n",
    "print(\"One-Hot Encoded:\")\n",
    "print(onehot_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating first datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pydicom as dicom\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import cv2\n",
    "\n",
    "def structure_for_train_csv(condition):\n",
    "        condition = condition.lower().replace(' ', '_').replace('/', '_')\n",
    "        return condition\n",
    "\n",
    "class SpinalDataset(Dataset):\n",
    "    def __init__(self, root_dir, coordinates_file, train, train_data, transform=None): # Setup the necessary attributes\n",
    "        self.root_dir = root_dir\n",
    "        self.coordinates = pd.read_csv(coordinates_file)\n",
    "        self.train_data = pd.read_csv(train_data)\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "\n",
    "        # Define label encoder and one hot encoder\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "        # Fit the label encoder and one hot encoder\n",
    "        conditions = [\"Normal/Mild\", \"Moderate\", \"Severe\"]\n",
    "\n",
    "        self.label_encoder.fit(conditions)\n",
    "        integer_encoded = self.label_encoder.transform(conditions).reshape(-1, 1)\n",
    "        self.onehot_encoder.fit(integer_encoded)\n",
    "\n",
    "        # Define sample weights\n",
    "        self.weights = {\"Normal/Mild\": 1, \"Moderate\": 2, \"Severe\": 4}\n",
    "\n",
    "    def __len__(self): # Returns the length of the Dataframe. More specifically numbers of rows in the dataset\n",
    "        return len(self.coordinates)\n",
    "    \n",
    "    def __getitem__(self, idx): # This method retrieves a single sample (images and label) from the dataset at the specified index (idx).\n",
    "        row = self.coordinates.iloc[idx]\n",
    "        study_id = row['study_id']\n",
    "        series_id = row['series_id']\n",
    "        instance = row['instance_number']\n",
    "        condition = row['condition']\n",
    "        level = row['level']\n",
    "        x = row['x']\n",
    "        y = row['y'] \n",
    "\n",
    "        # Construct the path to the DICOM\n",
    "        dicom_file_path = os.path.join(self.root_dir, self.train, str(study_id), str(series_id), f\"{instance}.dcm\")\n",
    "        \n",
    "        # Load the DICOM image, normalize it, and apply cropping or padding\n",
    "        # Change Needed: Instead of calling `self.load_dicom_image`, call `self.load_and_process_dicom_image` to include cropping/padding.\n",
    "        images = self.load_and_process_dicom_image(dicom_file_path)\n",
    "\n",
    "        if self.transform:\n",
    "            images = self.transform(images)\n",
    "\n",
    "        # Extract condition for the specified level\n",
    "        condition_column = f'{condition}_{level}'\n",
    "        condition_column = structure_for_train_csv(condition_column)\n",
    "        label_str = self.train_data.loc[self.train_data['study_id'] == study_id, condition_column].values[0]\n",
    "\n",
    "        # Encode the label\n",
    "        label_encoded = self.label_encoder.transform([label_str])\n",
    "        label_onehot = self.onehot_encoder.transform(label_encoded.reshape(-1, 1))\n",
    "        label = torch.tensor(label_onehot, dtype=torch.float32).squeeze()\n",
    "\n",
    "        print(f\"Label string: {label_str}\")\n",
    "        \n",
    "        # Calculate weight for the sample\n",
    "        weight = self.weights.get(label_str, 1)  # Default to 1 if condition not found\n",
    "\n",
    "        return images, label, weight  \n",
    "    \n",
    "    # Change Needed: Update this function to include the padding and cropping functionality\n",
    "    def load_and_process_dicom_image(self, file_path):\n",
    "        dicom = pydicom.dcmread(file_path)\n",
    "        image = dicom.pixel_array\n",
    "        \n",
    "        # Normalize the pixel values to [0, 1]\n",
    "        image = image.astype(np.float32) / image.max()\n",
    "\n",
    "        # Crop or pad the image as needed\n",
    "        if image.shape[0] > 512 or image.shape[1] > 512:\n",
    "            image, crop_top, crop_left = self.crop_image(image)\n",
    "        else:\n",
    "            image, crop_top, crop_left = self.pad_image(image)\n",
    "        \n",
    "        return image, crop_top, crop_left\n",
    "\n",
    "    # Change Needed: Update this method signature to accept an image array directly\n",
    "    def paddingOrCroppingImage(self, dcm_data):\n",
    "        # Example target size (height, width)\n",
    "        target_height, target_width = 512, 512\n",
    "\n",
    "        # Current image shape\n",
    "        current_height, current_width = dcm_data.shape\n",
    "\n",
    "        if current_height > target_height or current_width > target_width:\n",
    "            crop_top = (current_height - target_height) // 2\n",
    "            crop_bottom = crop_top + target_height\n",
    "            crop_left = (current_width - target_width) // 2\n",
    "            crop_right = crop_left + target_width\n",
    "\n",
    "            cropped_image = dcm_data[crop_top:crop_bottom, crop_left:crop_right]\n",
    "            return cropped_image\n",
    "        else:\n",
    "            # Calculate padding sizes\n",
    "            pad_height = max(0, target_height - current_height)\n",
    "            pad_width = max(0, target_width - current_width)\n",
    "\n",
    "            # Calculate the padding to apply to each side\n",
    "            pad_top = pad_height // 2\n",
    "            pad_bottom = pad_height - pad_top\n",
    "            pad_left = pad_width // 2\n",
    "            pad_right = pad_width - pad_left\n",
    "\n",
    "            # Apply padding with replicated borders\n",
    "            padded_image = cv2.copyMakeBorder(\n",
    "                dcm_data,\n",
    "                pad_top,\n",
    "                pad_bottom,\n",
    "                pad_left,\n",
    "                pad_right,\n",
    "                cv2.BORDER_REPLICATE\n",
    "            )\n",
    "\n",
    "            return padded_image  # Change Needed: Return the padded image directly without updating the DICOM metadata\n",
    "    \n",
    "    def adjust_coordinates(self, x, y):\n",
    "        \"\"\"\n",
    "        Adjusts x and y coordinates after cropping or padding.\n",
    "        \"\"\"\n",
    "        crop_left, crop_right, crop_top, crop_bottom =\n",
    "        if crop_left or crop_top:\n",
    "            # If cropped, adjust by subtracting crop offsets\n",
    "            adjusted_x = x - crop_left - crop_right\n",
    "            adjusted_y = y - crop_top - crop_bottom\n",
    "        else:\n",
    "            # If padded, adjust by adding padding offsets\n",
    "            adjusted_x = x + pad_left + pad_right\n",
    "            adjusted_y = y + pad_top + pad_bottom\n",
    "\n",
    "        return adjusted_x, adjusted_y\n",
    "\n",
    "# Example usage\n",
    "dataset = SpinalDataset(root_dir=INPUT_DIR, \n",
    "                        coordinates_file=f'{INPUT_DIR}/train_label_coordinates.csv', \n",
    "                        train='train_images',\n",
    "                        train_data=f'{INPUT_DIR}/train.csv')\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "for images, labels, weights in dataloader:\n",
    "    print(\"Images shape:\", images.shape)\n",
    "    print(\"Labels:\", labels)\n",
    "    print(\"Weights:\", weights)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
